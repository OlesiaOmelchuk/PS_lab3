---
title: 'P&S-2022: Lab assignment 3'
author: "Omelchuk Olesia, Vasylkiv Dmytro, Budii Tetiana"
output:
  html_document:
    df_print: paged
---

```{r}
id <- 15
set.seed(id)
```

# Task 1

# Task 2

# Task 3 (parameter estimation)

In problem 3 we have to verify that the interval estimates produced by the known rules indeed contain the parameter with probability equal to the confidence level.\
Here we have exponential distribution $\mathcal{E}(\lambda)$ with mean $1/\lambda$, so the good estimate of the parameter $\theta := 1/\lambda$ is the sample mean $\overline{x}$. Now let's find confidence intervals for $\theta$ in several different ways.

```{r}
theta <- id/10
alpha_vect <- c(0.1, 0.05, 0.01)
lambda <- 1/theta

M <- 10000
N <- 1000

# generate sample of size N, repeat it M times and write the results as N*M matrix
samples <- matrix(rexp(N*M, lambda), nrow = N)
# calculate sample mean in each column
sample_mean <- colMeans(samples)
# calculate sample standard deviation of each column
sample_sd <- apply(samples, 2, sd)
```

```{r}
# samples[0:10]
# sample_mean[0:10]
# sample_sd[0:10]
```

## Confidence interval for θ formed in 4 different ways:

### 3.1 (using the distribution of the statistics $2λn\overline{X}$)

Let's find the distribution of the statistics $2λn\overline{X}$\
$$2\lambda n\overline{X} = 2\lambda n\frac{X_1 + ... + X_n}{n} = 2\lambda(X_1 + ... + X_n) = 2\lambda X_1 + ... + 2\lambda X_n$$\
,where $X_1, ... X_n \sim \mathcal{E}(\lambda)$\
Then find the distribution of $2\lambda X$: $$F_{2\lambda X}(t) = P(2\lambda X <= t) = P(X <= \frac{t}{2\lambda}) = F_X(\frac{t}{2\lambda})$$\
$$f_{2\lambda X}(t) = f_X(\frac{t}{2\lambda}) * \frac{1}{2\lambda} = \lambda e^{-\lambda\frac{t}{2\lambda}}*\frac{1}{2\lambda} = \frac{1}{2}e^{-\frac{t}{2}}$$\
,so $Y = 2\lambda X \sim \mathcal{E}(\frac{1}{2})$\
Then $2\lambda n\overline{X} = Y_1 + ... + Y_n$, where $Y_1, ..., Y_n \sim \mathcal{E}(\frac{1}{2})$\
The sum of $n$ rv's with exponential distribution with parameter $\lambda = \frac{1}{2}$ result in gamma distribution: $$2\lambda n\overline{X} \sim \Gamma(n, \frac{1}{2}) \sim \chi_{2n}^{2}$$\

Now let's use quantiles of Chi-squared distribution to get the interval endpoints: $$P(\chi_{\frac{\alpha}{2}}^{2n} <= 2\lambda n\overline{X} <= \chi_{1-\frac{\alpha}{2}}^{2n}) = 1-\alpha$$\
Then we can solve the inequality and get the confidence interval for $\theta$: $$\frac{2n\overline{X}}{\chi_{1-\frac{\alpha}{2}}^{2n}} <= \theta <= \frac{2n\overline{X}}{\chi_{\frac{\alpha}{2}}^{2n}}$$

```{r}
for(alpha in alpha_vect){
  cat("For confidence level", 1-alpha, "\n")
  cat("    the fraction of CL's containing the parameter is",
      mean(theta >= 2*N*sample_mean/qchisq(1-alpha/2, 2*N) & theta <= 2*N*sample_mean/qchisq(alpha/2, 2*N)), "\n", sep = " ")
  cat("    maximal CL length is", 2*N*max(sample_mean)/qchisq(alpha/2, 2*N) - 2*N*max(sample_mean)/qchisq(1-alpha/2, 2*N), "\n", sep = " ")
  cat("    mean CL length is", 2*N*mean(sample_mean)/qchisq(alpha/2, 2*N) - 2*N*mean(sample_mean)/qchisq(1-alpha/2, 2*N), "\n", sep = " ")
}
```

### 3.2 (using the normal approximation for $\overline{X}$)

Now let's use the normal approximation $\mathcal{N}(\mu,\sigma^2)$ for $\overline{X}$; where parameters are $\mu = \theta, \sigma^2=s^2/n$, where $s^2=\theta^2$ is the population variance (variance of the original distribution $\mathcal{E}(\lambda)$). This means that we form the Z-statistics $Z := \sqrt{n}(\overline{X}-\mu)/\sigma = \sqrt{n}(\overline{X}-\theta)/\theta$ and then use the fact that it is approximately standard normal $\mathcal{N}(0,1)$ to find that:\
$$P(|\theta - \overline{X}| <= z_\beta\theta/\sqrt{n}) = P(|\overline{X}-\theta|\sqrt{n}/\theta <= z_\beta) = P(|Z| <= z_\beta) = 2\beta - 1$$\
So $\theta$ with is with probability $2\beta -1$ is in the interval: $$\overline{X} - x_\beta\theta/\sqrt{n} <= \theta <= \overline{X} + x_\beta\theta/\sqrt{n}$$\
The length of this interval will be:\
$$l = \overline{X} + x_\beta\theta/\sqrt{n} - (\overline{X} - x_\beta\theta/\sqrt{n}) = 2*x_\beta\theta/\sqrt{n}$$\

```{r}
for(alpha in alpha_vect){
  cat("For confidence level", 1-alpha, "\n")
  cat("    the fraction of CL's containing the parameter is",
      mean(abs(theta - sample_mean) <= qnorm(1 - alpha/2)*theta/sqrt(N)), "\n", sep = " ")
  cat("    maximal CL length is", 2*qnorm(1 - alpha/2)*theta/sqrt(N), "\n", sep = " ")
  cat("    mean CL length is", 2*qnorm(1 - alpha/2)*theta/sqrt(N), "\n", sep = " ")
}

```

### 3.3 (by solving the double inequality from previous part)

The confidence interval from the previous step uses the unknown variance $s^2=\theta^2$, so we can solve the double inequality

```{r}
for(alpha in alpha_vect){
  cat("For confidence level", 1-alpha, "\n")
  cat("    the fraction of CL's containing the parameter is",
      mean(theta >= sample_mean/(1 + qnorm(1 - alpha/2)/sqrt(N)) & theta <= sample_mean/(1 - qnorm(1 - alpha/2)/sqrt(N))), "\n", sep = " ")
  cat("    maximal CL length is", max(sample_mean)/(1 - qnorm(1 - alpha/2)/sqrt(N)) - max(sample_mean)/(1 + qnorm(1 - alpha/2)/sqrt(N)), "\n", sep = " ")
  cat("    mean CL length is", mean(sample_mean)/(1 - qnorm(1 - alpha/2)/sqrt(N)) - mean(sample_mean)/(1 + qnorm(1 - alpha/2)/sqrt(N)), "\n", sep = " ")
}
```

### 3.4 (using Student t-distribution)

```{r}
for(alpha in alpha_vect){
  cat("For confidence level", 1-alpha, "\n")
  cat("    the fraction of CL's containing the parameter is",
      mean(abs(theta - sample_mean) <= qt(1-alpha/2, N-1)*sample_sd/sqrt(N)), "\n", sep = " ")
  cat("    maximal CL length is", 2*qt(1-alpha/2, N-1)*max(sample_sd)/sqrt(N), "\n", sep = " ")
  cat("    mean CL length is", 2*qt(1-alpha/2, N-1)*mean(sample_sd)/sqrt(N), "\n", sep = " ")
}
```

### Conclusion

While testing on different values for M and N we can see that the bigger value, the closer the empirical fraction of CL's containing the parameter is to the actual confidence level.\
When it comes to selecting one out of three methods for finding confidence interval for parameter $\theta:= 1/\lambda$ for exponential distribution, based on the results we can see that first method works the best and gives the closest values to the actual confidence levels. This is because the sum of rv's with exponential distribution can be easily described as Gamma distribution and than as Chi-squared distribution.\
Second and third methods aren't that good, on the other hand, as actually they use the same inequality which is dependent on unknown parameter variance

# Task 4

Repeat parts (2)–(4) of Problem 3 (with corresponding amendments) for a Poisson distribution P(θ).
Task and Directions remain he same; in other words, you have to check that confidence intervals constructed there
contain the parameter θ with prescribed probability.
```{r}
set.seed(15)

lambda = 1.5

matrix_size =  c(100, 1000, 10000)

success_count = 0

print_result <- function(lower, upper, sample_mean) {
  cat("For confidence level", 1 - a, "where n =", n, ":\n")
    cat("    CI is [", lower, ",", upper, "]\n")
    cat("    The fraction of CI's containing the parameter is", length(sample_mean[lower <= sample_mean & sample_mean <= upper]) / n, "\n\n\n")
}
```

# (2)
Using the Normal approximation :
```{r}
for (n in matrix_size) {
  x <- matrix(rpois(n*n, lambda), nrow = n)
  sample_mean <- colMeans(x)
  sample_sd <- sd(x)
  
  for (a in c(0.1, 0.05, 0.01)) {
    lower <- mean(sample_mean) - qnorm(1 - a/2) * sample_sd / sqrt((n))

    upper <- mean(sample_mean) + qnorm(1 - a/2) * sample_sd / sqrt((n))
    
    print_result(lower, upper, sample_mean)
  }
}
```

# (3)
By solving the $|\overline{X} - \theta| <= \sqrt(\theta/n) * z_\beta$ equation for $\theta$ as follows : 
$$\overline{X} - \theta <= \sqrt(\theta/n)*z_\beta$$ and $$\overline{X} - \theta >= \sqrt(\theta/n)*z_\beta$$. Solving two quadratic equations $\theta + \sqrt\theta*(z_\beta/\sqrt(n)) - \overline{X}=0$ and  $\theta + \sqrt\theta*(z_\beta/\sqrt(n)) - \overline{X}=0$ and taking proper values for $\theta$, we get $$\theta_1 = (\sqrt(z_\beta^2/n+4*\overline{X}) - z_\beta/\sqrt n)/2$$ and $$\theta_2 = (\sqrt(z_\beta^2/n+4*\overline{X}) + z_\beta/\sqrt n)/2$$. Those are our bounds for $\theta$.
```{r}
for (n in matrix_size) {
  x <- matrix(rpois(n*n, lambda), nrow = n)
  sample_mean <- colMeans(x)
  sample_sd <- sd(x)
  
  for (a in c(0.1, 0.05, 0.01)) {
    discriminant <- qnorm(1 - a/2) / n + 4 * mean(sample_mean)
    
    lower <-(sqrt(discriminant)/2 - qnorm(1-a/2)/(2*sqrt(n)))^2
    
    upper <- (sqrt(discriminant)/2 + qnorm(1-a/2)/(2*sqrt(n)))^2
    
    print_result(lower, upper, sample_mean)
  }
}

```

# (4)
Using Students t-distribution for Poisson :
```{r}
for (n in matrix_size) {
  x <- matrix(rpois(n*n, lambda), nrow = n)
  sample_mean <- colMeans(x)
  sample_sd <- sd(x)

  for (a in c(0.1, 0.05, 0.01)) {
    lower <- mean(sample_mean) - sample_sd * qt(1-a/2, n - 1) / sqrt(n)
    
    upper <- mean(sample_mean) + sample_sd * qt(1-a/2, n - 1) / sqrt(n)
    
    print_result(lower, upper, sample_mean)
  }
}

```
### Conclusion

As in Task 3, we can see that the bigger size of our sample is, the closer is the result of our computations to the expected one. As for the best method of finding the confidence interval for $\theta$, you can see that the results are pretty similar and folow the same tendencies, but when comes to the estimation of $n$ great enough, the third method generates the closest fractions to the expected result, on the opposite of the previous task case.
