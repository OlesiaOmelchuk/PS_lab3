---
title: 'P&S-2022: Lab assignment 3'
author: "Omelchuk Olesia, Vasylkiv Dmytro, Budii Tetiana"
output:
  html_document:
    df_print: paged
---

```{r}
id <- 15
set.seed(id)
```

# Task1

1.  Estimate numerically the probability $\hat{p_n}$ of the event that your TLN occurs in a random digit sequence d1d2d3 . . . dn.\
    Hint: Such a sequence can be generated with R command sample(0:9, n, replace=T); you will need to generate a sample of such sequences of sufficiently large size N\

```{r}
TLN = 015
K = 1000
counter <- c(0, 0, 0)
#N <- c(100, 150, 5)
N <- c(100, 200, 1000)
for (i in(1:K)){
  for (j in (1:3)){
    n <- N[j]
    rand_sample <- c(sample(0:9, n, replace=T))
    #print(rand_sample)
    my_range <- 1:(n-3)
    for (index in my_range){
      dig1 <- rand_sample[index]
      dig2 <- rand_sample[index+1]
      dig3 <- rand_sample[index+2]
      if (dig1 == 0 && dig2 == 1 && dig3 == 5){
        counter[j] = counter[j] + 1
        break
      }
    }
  }
}
prob <- c(counter[1]/K, counter[2]/K,counter[3]/K)

cat("The probabilty that TLN occurs in a random sequence of digits of length 100:\n", prob[1], "\n\n")
cat("The probabilty that TLN occurs in a random sequence of digits of length 200:\n", prob[2], "\n\n")
cat("The probabilty that TLN occurs in a random sequence of digits of length 1000:\n", prob[3], "\n\n")
```

2.  Identify the the Markov chain structure with four states S0, S1, S2, S3 in this sequence with Sk denoting the number of correct last digits (id = 015 -\> S0 ="\*", S1 ="0", S2 ="01", S3 ="015"). Determine the transition probabilities matrix P and find the limiting probability $p_n$ for the state "015"

The transition probabilities matrix P: $$
P = 
\begin{pmatrix}
0.9 & 0.1 & 0 & 0\\
0.8 & 0.1 & 0.1 & 0\\
0.8 & 0.1 & 0 & 0.1\\
0.9 & 0.1 & 0 & 0\\
\end{pmatrix}
$$ Solving limiting probability $$
{\pi_0 = 0.9 \pi_0 + 0.8\pi_1 + 0.8\pi_2 + 0.9\pi_3\\
\pi_1 = 0.1\pi_0 + 0.1\pi_1 + 0.1\pi_2 + 0.1\pi_3\\
\pi_2 = 0.1\pi_1\\
\pi_3 = 0.1\pi_2\\
\pi_0 + \pi_1 + \pi_2 + \pi_3 = 1}
$$ Solution: $$
{\pi_0 = 0.889\\
\pi_1 = 0.1\\
\pi_2 = 0.01\\
\pi_3 = 0.001}
$$ We see that limiting probability and estimated probability are different, because limiting probability is a probabilty, that after n steps we will be at state $S_3$. It means the last 3 digits will be $015$. Estimated probability is a probability that $015$ appears at least one time.

3.  Determine approximately the sample size N which guarantees that the absolute error $|\hat{p_n} − p_n|$ of the estimate $\hat{p_n}$ is below 0.03 with confidence level of at least 95 percent. Rerun the experiments for n = 1000 with the determined size N to illustrate the confidence interval and confidence level. Hint: estimate the standard deviation of the corresponding random variable by the standard error of the sample.

To begin with, we will find $\sigma$.

```{r}
set.seed(15)
N = 1000
result_samle<-c()
for (i in 1:1000){
  rand_sample <- c(sample(0:9, N, replace=T))
  my_range <- 1:(N-2)
  found = FALSE
  for (index in my_range){
    dig1 <- rand_sample[index]
    dig2 <- rand_sample[index+1]
    dig3 <- rand_sample[index+2]
    if (dig1 == 0 && dig2 == 1 && dig3 == 5){
      counter[j] = counter[j] + 1
      result_samle <- c(result_samle, 1)
      found = TRUE
      break
    }
  }
  if (!found) {
    result_samle <- c(result_samle, 0)
  }
}
print(sd(result_samle))
```

So $\sigma = 0.4827754$ for n=1000

$$|\hat{p} - p| < 0.03$$\
$$1- \alpha = P\{|\hat{p} - p| \le \frac{\sigma}{\sqrt(n)}*Z_{1-*\frac{\alpha}{2}}\}$$ $$\frac{\sigma}{\sqrt(n)}Z_{1-\frac{\alpha}{2}} < 0.03$$\
$$n > \frac{\sigma^2 * Z_{1-\frac{\alpha}{2}}^2}{(0.03)^2}$$\

$$Z_{1-\frac{\alpha}{2}} = 1.96$$\

$$n \ge 1000$$\
Let's find the probability that when n = 1000, our TLN will appear in a random sequence

```{r}
set.seed(15)
n = 1000
prob = 0
N = 1000
count = 0
for (i in c(1:n)){
  counter = 0
  for (j in c(1:1000)){
    rand_sample <- c(sample(0:9, N, replace=T))
    for (index in c(1:(N-2))){
      dig1 <- rand_sample[index]
      dig2 <- rand_sample[index+1]
      dig3 <- rand_sample[index+2]
      if (dig1 == 0 && dig2 == 1 && dig3 == 5){
        counter = counter + 1
        break
      }
    }
  }
  p = counter/1000
  if (abs(p - 0.628)<0.03){
    count = count + 1
  }
}
prob = count/n
print(prob)
```

As we can see, this probability is $0.945$, which is close to \$ 1 - \alpha = 0.95\$

# Task2

In the setting of Problem 1, assume that the random digit generation stops at the first occurrence of the TLN (i.e., that the state S4 of the Markov chain is now absorbing). In this problem, you will estimate the average length of such sequences (i.e., the average time till absorption in the Markov chain).

1.  Make necessary amendments to the transition probabilities matrix P above and solve the corresponding system to find the expected time E(T) till absorption

The transition probabilities matrix P: $$
    P = 
    \begin{pmatrix}
        0.9 & 0.1 & 0 & 0\\
        0.8 & 0.1 & 0.1 & 0\\
        0.8 & 0.1 & 0 & 0.1\\
        0 & 0 & 0 & 1\\
    \end{pmatrix}
$$ Solving a system to find the expected time E(T) till absorption

$$
{\mu_0 = 1 + 0.9 \mu_0 + 0.1\mu_1\\
\mu_1 = 1 + 0.8\mu_0 + 0.1\mu_1 + 0.1\mu_2\\
\mu_2 = 1 + 0.8\mu_0 + 0.1\mu_1 + 0.1\mu_3\\
\mu_3 = 0}
$$ Solution: $$
{\mu_0 = 1000\\
\mu_1 = 990\\
\mu_2 = 900\\
\mu_3 = 0}
$$ As we can see, $\mu_0 = 1000$, so $E(T) = 1000$

2.  Estimate numerically the expected length E(T) till the first occurrence of the TLN by running a sufficiently large number N of experiments. Hint: Clearly, the unbiased estimator for $\theta := E(T)$ is the sample mean $\hat{\theta} = \overline{T} = \frac{1}{N}*(T_1 + T_2 + ... + T_N)$

```{r}
set.seed(15)
N = 2000
total_sum = 0
for (i in (1:N)){
  rand_sample <- c(sample(0:9, 3, replace=T))
  i = 3
  while(rand_sample[i-2] != 0 | rand_sample[i-1] != 1 | rand_sample[i] != 5){
    rand_sample <- c(rand_sample, sample(0:9, 1, replace=T))
    i = i+1
  }
  total_sum = total_sum + length(rand_sample)
}

exp_time = total_sum/N
print(exp_time)
```

As we can see, in practice $E(T) = 1006.792$. This is very close to the theoretical value we found above

3.  Find the sample size N which guarantees that the absolute error $|\hat{\theta} - \theta|$ of the estimate does not exceed 10 with confidence level of at least 95 percent. Hint: use Chebyshev inequality and estimate the standard deviation of T by the standard error of the sample $T_1, T_2, ... T_N$

# Task 3 (parameter estimation)

In problem 3 we have to verify that the interval estimates produced by the known rules indeed contain the parameter with probability equal to the confidence level.\
Here we have exponential distribution $\mathcal{E}(\lambda)$ with mean $1/\lambda$, so the good estimate of the parameter $\theta := 1/\lambda$ is the sample mean $\overline{x}$. Now let's find confidence intervals for $\theta$ in several different ways.

```{r}
theta <- id/10
alpha_vect <- c(0.1, 0.05, 0.01)
lambda <- 1/theta

M <- 10000
N <- 1000

# generate sample of size N, repeat it M times and write the results as N*M matrix
samples <- matrix(rexp(N*M, lambda), nrow = N)
# calculate sample mean in each column
sample_mean <- colMeans(samples)
# calculate sample standard deviation of each column
sample_sd <- apply(samples, 2, sd)
```

```{r}
# samples[0:10]
# sample_mean[0:10]
# sample_sd[0:10]
```

## Confidence interval for θ formed in 4 different ways:

### 3.1 (using the distribution of the statistics $2λn\overline{X}$)

Let's find the distribution of the statistics $2λn\overline{X}$\
$$2\lambda n\overline{X} = 2\lambda n\frac{X_1 + ... + X_n}{n} = 2\lambda(X_1 + ... + X_n) = 2\lambda X_1 + ... + 2\lambda X_n$$\
,where $X_1, ... X_n \sim \mathcal{E}(\lambda)$\
Then find the distribution of $2\lambda X$: $$F_{2\lambda X}(t) = P(2\lambda X <= t) = P(X <= \frac{t}{2\lambda}) = F_X(\frac{t}{2\lambda})$$\
$$f_{2\lambda X}(t) = f_X(\frac{t}{2\lambda}) * \frac{1}{2\lambda} = \lambda e^{-\lambda\frac{t}{2\lambda}}*\frac{1}{2\lambda} = \frac{1}{2}e^{-\frac{t}{2}}$$\
,so $Y = 2\lambda X \sim \mathcal{E}(\frac{1}{2})$\
Then $2\lambda n\overline{X} = Y_1 + ... + Y_n$, where $Y_1, ..., Y_n \sim \mathcal{E}(\frac{1}{2})$\
The sum of $n$ rv's with exponential distribution with parameter $\lambda = \frac{1}{2}$ result in gamma distribution: $$2\lambda n\overline{X} \sim \Gamma(n, \frac{1}{2}) \sim \chi_{2n}^{2}$$\

Now let's use quantiles of Chi-squared distribution to get the interval endpoints: $$P(\chi_{\frac{\alpha}{2}}^{2n} <= 2\lambda n\overline{X} <= \chi_{1-\frac{\alpha}{2}}^{2n}) = 1-\alpha$$\
Then we can solve the inequality and get the confidence interval for $\theta$: $$\frac{2n\overline{X}}{\chi_{1-\frac{\alpha}{2}}^{2n}} <= \theta <= \frac{2n\overline{X}}{\chi_{\frac{\alpha}{2}}^{2n}}$$

```{r}
for(alpha in alpha_vect){
  cat("For confidence level", 1-alpha, "\n")
  cat("    the fraction of CL's containing the parameter is",
      mean(theta >= 2*N*sample_mean/qchisq(1-alpha/2, 2*N) & theta <= 2*N*sample_mean/qchisq(alpha/2, 2*N)), "\n", sep = " ")
  cat("    maximal CL length is", 2*N*max(sample_mean)/qchisq(alpha/2, 2*N) - 2*N*max(sample_mean)/qchisq(1-alpha/2, 2*N), "\n", sep = " ")
  cat("    mean CL length is", 2*N*mean(sample_mean)/qchisq(alpha/2, 2*N) - 2*N*mean(sample_mean)/qchisq(1-alpha/2, 2*N), "\n", sep = " ")
}
```

### 3.2 (using the normal approximation for $\overline{X}$)

Now let's use the normal approximation $\mathcal{N}(\mu,\sigma^2)$ for $\overline{X}$; where parameters are $\mu = \theta, \sigma^2=s^2/n$, where $s^2=\theta^2$ is the population variance (variance of the original distribution $\mathcal{E}(\lambda)$). This means that we form the Z-statistics $Z := \sqrt{n}(\overline{X}-\mu)/\sigma = \sqrt{n}(\overline{X}-\theta)/\theta$ and then use the fact that it is approximately standard normal $\mathcal{N}(0,1)$ to find that:\
$$P(|\theta - \overline{X}| <= z_\beta\theta/\sqrt{n}) = P(|\overline{X}-\theta|\sqrt{n}/\theta <= z_\beta) = P(|Z| <= z_\beta) = 2\beta - 1$$\
So $\theta$ with is with probability $2\beta -1$ is in the interval: $$\overline{X} - x_\beta\theta/\sqrt{n} <= \theta <= \overline{X} + x_\beta\theta/\sqrt{n}$$\
The length of this interval will be:\
$$l = \overline{X} + x_\beta\theta/\sqrt{n} - (\overline{X} - x_\beta\theta/\sqrt{n}) = 2*x_\beta\theta/\sqrt{n}$$\

```{r}
for(alpha in alpha_vect){
  cat("For confidence level", 1-alpha, "\n")
  cat("    the fraction of CL's containing the parameter is",
      mean(abs(theta - sample_mean) <= qnorm(1 - alpha/2)*theta/sqrt(N)), "\n", sep = " ")
  cat("    maximal CL length is", 2*qnorm(1 - alpha/2)*theta/sqrt(N), "\n", sep = " ")
  cat("    mean CL length is", 2*qnorm(1 - alpha/2)*theta/sqrt(N), "\n", sep = " ")
}

```

### 3.3 (by solving the double inequality from previous part)

The confidence interval from the previous step uses the unknown variance $s^2=\theta^2$, so we can solve the double inequality and get another confidence interval that is independent of the unknown parameter: $$|\theta - \overline{X}| <= z_\beta\theta/\sqrt{n}$$\
$$\frac{\overline{X}}{1 + \frac{z_\beta}{\sqrt{n}}} <= \theta <= \frac{\overline{X}}{1 - \frac{z_\beta}{\sqrt{n}}}$$

```{r}
for(alpha in alpha_vect){
  cat("For confidence level", 1-alpha, "\n")
  cat("    the fraction of CL's containing the parameter is",
      mean(theta >= sample_mean/(1 + qnorm(1 - alpha/2)/sqrt(N)) & theta <= sample_mean/(1 - qnorm(1 - alpha/2)/sqrt(N))), "\n", sep = " ")
  cat("    maximal CL length is", max(sample_mean)/(1 - qnorm(1 - alpha/2)/sqrt(N)) - max(sample_mean)/(1 + qnorm(1 - alpha/2)/sqrt(N)), "\n", sep = " ")
  cat("    mean CL length is", mean(sample_mean)/(1 - qnorm(1 - alpha/2)/sqrt(N)) - mean(sample_mean)/(1 + qnorm(1 - alpha/2)/sqrt(N)), "\n", sep = " ")
}
```

### 3.4 (using Student t-distribution)

Another way to get rid of the dependence on $\theta$ in part 2 is to estimate $s$ via the sample standard error and use approximation of $\overline{X}$ via Student t-distribution: $$Z:=\frac{\overline{X}-\theta}{\theta}\sqrt{n} \sim \mathcal{N}(0,1)$$\
$$\frac{\overline{X}-\theta}{s}\sqrt{n} \sim \mathcal{T}(n-1)$$\
And then we can find the approximate confidence interval for $\theta$ of confidence level $1-\alpha$ in case of exponential distribution with unknown parameter $s$:\
$$-t_{1-\frac{\alpha}{2}}^{n-1} <= \frac{\overline{X}-\theta}{s}\sqrt{n} <= t_{1-\frac{\alpha}{2}}^{n-1}$$\
$$\overline{X} - \frac{s}{\sqrt{n}}t_{1-\frac{\alpha}{2}}^{n-1} <= \theta <= \overline{X} + \frac{s}{\sqrt{n}}t_{1-\frac{\alpha}{2}}^{n-1}$$\

```{r}
for(alpha in alpha_vect){
  cat("For confidence level", 1-alpha, "\n")
  cat("    the fraction of CL's containing the parameter is",
      mean(abs(theta - sample_mean) <= qt(1-alpha/2, N-1)*sample_sd/sqrt(N)), "\n", sep = " ")
  cat("    maximal CL length is", 2*qt(1-alpha/2, N-1)*max(sample_sd)/sqrt(N), "\n", sep = " ")
  cat("    mean CL length is", 2*qt(1-alpha/2, N-1)*mean(sample_sd)/sqrt(N), "\n", sep = " ")
}
```

### Conclusion

While testing on different values for M and N we can see that the bigger value, the closer the empirical fraction of CL's containing the parameter is to the actual confidence level.\
When it comes to selecting one out of three methods for finding confidence interval for parameter $\theta:= 1/\lambda$ for exponential distribution, based on the results we can see that first method works the best and gives the closest values to the actual confidence levels. This is because the sum of rv's with exponential distribution can be easily described as Gamma distribution and than as Chi-squared distribution.\
Second and third methods aren't that good, on the other hand, as actually they use the same inequality which is dependent on unknown parameter variance

# Task 4

Repeat parts (2)--(4) of Problem 3 (with corresponding amendments) for a Poisson distribution P(θ). Task and Directions remain he same; in other words, you have to check that confidence intervals constructed there contain the parameter θ with prescribed probability.

```{r}

lambda = 1.5

matrix_size =  c(100, 1000, 10000)

print_result <- function(lower, upper, sample_mean) {
  cat("For confidence level", 1 - a, "where n =", n, ":\n")
    cat("    CI is [", lower, ",", upper, "]\n")
    cat("    The fraction of CI's containing the parameter is", length(sample_mean[lower <= sample_mean & sample_mean <= upper]) / n, "\n\n\n")
}
```

# (2)

Using the Normal approximation :

```{r}
for (n in matrix_size) {
  x <- matrix(rpois(n*n, lambda), nrow = n)
  sample_mean <- colMeans(x)
  sample_sd <- sd(x)
  
  for (a in c(0.1, 0.05, 0.01)) {
    lower <- mean(sample_mean) - qnorm(1 - a/2) * sample_sd / sqrt((n))

    upper <- mean(sample_mean) + qnorm(1 - a/2) * sample_sd / sqrt((n))
    
    print_result(lower, upper, sample_mean)
  }
}
```

# (3)

By solving the $|\overline{X} - \theta| <= \sqrt(\theta/n) * z_\beta$ equation for $\theta$ as follows : $$\overline{X} - \theta <= \sqrt(\theta/n)*z_\beta$$ and $$\overline{X} - \theta >= \sqrt(\theta/n)*z_\beta$$. Solving two quadratic equations $\theta + \sqrt\theta*(z_\beta/\sqrt(n)) - \overline{X}=0$ and $\theta + \sqrt\theta*(z_\beta/\sqrt(n)) - \overline{X}=0$ and taking proper values for $\theta$, we get $$\theta_1 = (\sqrt(z_\beta^2/n+4*\overline{X}) - z_\beta/\sqrt n)/2$$ and $$\theta_2 = (\sqrt(z_\beta^2/n+4*\overline{X}) + z_\beta/\sqrt n)/2$$. Those are our bounds for $\theta$.

```{r}
for (n in matrix_size) {
  x <- matrix(rpois(n*n, lambda), nrow = n)
  sample_mean <- colMeans(x)
  sample_sd <- sd(x)
  
  for (a in c(0.1, 0.05, 0.01)) {
    discriminant <- qnorm(1 - a/2) / n + 4 * mean(sample_mean)
    
    lower <-(sqrt(discriminant)/2 - qnorm(1-a/2)/(2*sqrt(n)))^2
    
    upper <- (sqrt(discriminant)/2 + qnorm(1-a/2)/(2*sqrt(n)))^2
    
    print_result(lower, upper, sample_mean)
  }
}

```

# (4)

Using Students t-distribution for Poisson :

```{r}
for (n in matrix_size) {
  x <- matrix(rpois(n*n, lambda), nrow = n)
  sample_mean <- colMeans(x)
  sample_sd <- sd(x)

  for (a in c(0.1, 0.05, 0.01)) {
    lower <- mean(sample_mean) - sample_sd * qt(1-a/2, n - 1) / sqrt(n)
    
    upper <- mean(sample_mean) + sample_sd * qt(1-a/2, n - 1) / sqrt(n)
    
    print_result(lower, upper, sample_mean)
  }
}

```

### Conclusion

As in Task 3, we can see that the bigger size of our sample is, the closer is the result of our computations to the expected one. As for the best method of finding the confidence interval for $\theta$, you can see that the results are pretty similar and folow the same tendencies, but when comes to the estimation of $n$ great enough, the third method generates the closest fractions to the expected result, on the opposite of the previous task case.
